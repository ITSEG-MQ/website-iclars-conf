---
layout: default
title: Home
nav: home
---

<style>
h2 {
    line-height: 1.4; 
    word-break: break-word;
}
</style>

<h3>About ICLARS</h3>

<p>The International Conference on Learning and Reasoning Systems (ICLARS) is the premier venue dedicated to advancing the scientific foundations and engineering practice of tightly integrated learning–reasoning systems. ICLARS brings together researchers and professionals committed to building safe, interpretable, and domain-grounded AI systems that move beyond today’s brittle pattern-matching paradigms.</p>

<p>Traditional neurosymbolic approaches often treat neural and symbolic components as separate, loosely connected modules. In contrast, ICLARS promotes a unified vision where neural and symbolic representations co-evolve: neural models support the evolution of symbolic structures and abstractions, while symbolic knowledge constrains and guides neural training, enabling sample-efficient learning and explicit domain knowledge acquisition. This deeper integration offers principled safety guarantees that cannot be achieved through data alignment alone.</p>

<p>ICLARS serves as the global forum for publishing cutting-edge theory, methods, and systems that demonstrate real-world impact—particularly in autonomous systems, cyber-physical systems, robotics, and any domain requiring reliable reasoning under uncertainty.</p>

<h3>Topics of Interest</h3>

<p>ICLARS invites contributions across all aspects of integrated learning and reasoning, including but not limited to:</p>

<h4>Foundations & Theory</h4>

<ul>
    <li>Unified paradigms for neuro-symbolic integration</li>
    <li>Executable semantics for learning–reasoning systems</li>
    <li>Concept formation, grounding, and knowledge induction</li>
    <li>Theoretical guarantees for safety, robustness, and correctness</li>
</ul>

<h4>Learning–Reasoning Integration</h4>

<ul>
    <li>Symbolically guided neural training and inference</li>
    <li>Neural models that induce, evolve, or refine symbolic rules</li>
    <li>Structured, low-data, and knowledge-driven learning</li>
    <li>Program synthesis, DSLs, and architecture-level unification</li>
</ul>

<h4>Trustworthy & Safe AI</h4>

<ul>
    <li>Formal verification for integrated AI systems</li>
    <li>Runtime monitoring and explainable reasoning pipelines</li>
    <li>Safety guardrails for ML-enabled autonomous systems</li>
    <li>Robustness, causality, and out-of-distribution generalization</li>
</ul>

<h4>Systems & Platforms</h4>

<ul>
    <li>Scalable architectures for neuro-symbolic pipelines</li>
    <li>Compilers, runtimes, and execution engines</li>
    <li>Benchmarks, datasets, and evaluation methodologies</li>
    <li>Real-world deployments in CPS, robotics, ADS, UAVs, and AI-enabled software</li>
</ul>

<h4>Applications</h4>

<ul>
    <li>Autonomous driving and aerial robotics</li>
    <li>Human–AI teaming and interactive agents</li>
    <li>Scientific discovery, digital twins, and simulation</li>
    <li>Safety-critical systems in healthcare, finance, and infrastructure</li>
</ul>
<!-- <style>
/* 修复 h2 标题换行重叠问题 */
h2 {
    line-height: 1.4; 
    word-break: break-word;
}
</style>

<h2>AAAI Bridge Program: Making Embodied AI Reliable with Testing and Formal Verification</h2>

<h3>Call for Participation</h3>

<h4>Description of bridge</h4>

<p>
    This bridge addresses one of the most urgent challenges in AI: how to make embodied AI systems—such as autonomous vehicles, UAVs, and robots—interpretable, testable, and formally verifiable. While modern AI models excel in perception and decision-making, they pose significant challenges for traditional verification techniques, raising critical risks in safety-sensitive domains. The goal of this bridge is to unite diverse communities—AI/ML, formal methods, software engineering, robotics, and cyber-physical systems—in developing a shared roadmap for reliable embodied AI. Participants will engage with cutting-edge approaches in neurosymbolic reasoning, LLM-guided specification mining, scenario-based testing, compositional verification, and robustness under uncertainty, and explore their potential to support certification and assurance of AI-enabled autonomy.
</p>

<h4>Topics</h4>
<ul>
    <li>Testability and verifiability of AI-enabled autonomy</li>
    <li>LLM-guided specification mining and scenario generation</li>
    <li>White-box and compositional verification of neural and neurosymbolic components</li>
    <li>Neurosymbolic architectures for modular reasoning and distillation</li>
    <li>Robustness under sensing noise, ambiguous instructions, and human–robot interaction</li>
    <li>Formal guardrails for LLMs and VLMs in embodied decision-making</li>
</ul>

<h4>Format of bridge</h4>
<p>
    This one-day event will combine tutorials, keynote talks, technical presentations, panel discussions, and interactive breakout sessions. The morning program will feature tutorials and invited keynotes from leaders in neurosymbolic AI, formal verification, and embodied autonomy, followed by selected paper presentations. The afternoon will include a panel on certification challenges and breakout discussions organized around open problems such as scenario-based testing, compositional verification, and robustness under uncertainty.
</p>

<h4>Attendance</h4>
<p>
    We anticipate 50–80 participants, with priority given to researchers and practitioners in AI, robotics, formal methods, and CPS. Early-career researchers and graduate students are strongly encouraged to participate, with mentoring opportunities included.
</p>

<h4>Submission requirements</h4>
<p>
    We invite 2–4 page extended abstracts or position papers describing research advances, tools, or case studies relevant to reliable embodied AI. Submissions should emphasize how the work enhances testability, interpretability, or verification of embodied AI. Accepted contributions will be presented as talks, posters, or lightning sessions.
</p>

<h4>Submission site information</h4>
<p>
    Submissions should be made via https://easychair.org/conferences/?conf=aaai26bridgereai
</p>

<h4>Bridge Chairs</h4>
<ul>
    <li>A/Prof. Xi (James) Zheng, Macquarie University (james.zheng@mq.edu.au)</li>
    <li>Prof. Corina S. Pasareanu, Carnegie Mellon University / NASA Ames (corina.pasareanu@cmu.edu)</li>
    <li>Assistant Prof. Ivan Ruchkin, University of Florida (iruchkin@ece.ufl.edu)</li>
    <li>Prof. Archan Misra, Singapore Management University (archanm@smu.edu.sg)</li>
</ul>

<h4>Bridge Committee</h4>

<ul>
    <li>Ziyang Li (Johns Hopkins University)</li>
    <li>David Lo (Singapore Management University)</li>
    <li>Djordje Žikelić (Singapore Management University)</li>
    <li>Anna Lukina (Delft University of Technology)</li>
    <li>Aloysius K. Mok (University of Texas at Austin)</li>
    <li>Kenneth Kwok (A-STAR, Singapore)</li>
    <li>Daniel Neider (TU Dortmund University)</li>
    <li>Vijay Ganesh (Georgia Institute of Technology)</li>
    <li>Biplav Srivastava (University of South Carolina)</li>
    <li>Guy Van Den Broeck (University of California, Los Angeles)</li>
    <li>Basura Fernando (A-STAR, Singapore)</li>
</ul>

<h4>Important Dates</h4>
<ul>
    <li>Submissions due: October 31, 2025</li>
    <li>Notifications: November 14, 2025</li>
</ul> -->
